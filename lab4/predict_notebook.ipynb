{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "A Machine Learning Prediction Framework in an IPython Notebook"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook shows how we go about a prediction model from some labeled data. In machine learning, this is often called \"supervised learning.\" Some of the code is implementation-specific to our task (entity resolution of a dataset from Locu and Foursquare), but we think that the broad outlines are generally applicable to many prediction models."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Third-Party and Custom Libraries"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will include a few standard libraries for our work, including NumPy and models from scikit-learn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A big part of our work is extracting features from our dataset. These feature-extracting functions currently exist in two Python files, utils.py and feature_library.py, included in the folder of this notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utils\n",
      "import feature_library"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In our specific problem, we want to match businesses from two organizations that collect this information. Given two sets of businesses, A and B, we want to find a match between businesses in A and B. We also happen to know that there is a maximum of one match for each business.\n",
      "\n",
      "This lends itself nicely to <a href=\"http://en.wikipedia.org/wiki/Perfect_matching\">graph matching</a> algorithms. We use the Hungarian algorithm, which is available in a third party library."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import hungarian"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Helper Functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have a number of helper functions that transform our data into the form required by scikit-learn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def weights_to_matching(p, index):\n",
      "    # Convert the indices to numbers\n",
      "    index_a = {}\n",
      "    reverse_a = []\n",
      "    index_b = {}\n",
      "    reverse_b = []\n",
      "\n",
      "    for (k_a, k_b) in index:\n",
      "        if k_a not in index_a:\n",
      "            index_a[k_a] = len(index_a)\n",
      "            reverse_a.append(k_a)\n",
      "        if k_b not in index_b:\n",
      "            index_b[k_b] = len(index_b)\n",
      "            reverse_b.append(k_b)\n",
      "\n",
      "    weights = np.zeros((len(index_a), len(index_b)))\n",
      "    for k in range(len(p)): \n",
      "        (k_a, k_b) = index[k]\n",
      "        weights[index_a[k_a]][index_b[k_b]] = p[k][1]\n",
      "        \n",
      "    matching = hungarian.lap(-weights)[0]\n",
      "\n",
      "    # matches are stored in a dictionary\n",
      "    res = {}\n",
      "    for i in range(len(matching)):\n",
      "        locu = reverse_a[i]\n",
      "        four = reverse_b[matching[i]]\n",
      "        w = weights[i][matching[i]]\n",
      "        res[(locu, four)] = w\n",
      "    return res\n",
      "\n",
      "def score_matching(pred_matching, true_matching, thresh):\n",
      "    falsePos = 0\n",
      "    truePos = 0\n",
      "    missed = []\n",
      "\n",
      "    for k in true_matching.iterkeys():\n",
      "        if k in pred_matching and pred_matching[k] > thresh:\n",
      "            truePos += 1\n",
      "        else:\n",
      "            missed.append(k)\n",
      "\n",
      "    total_predictions = 0\n",
      "    for v in pred_matching.itervalues():\n",
      "        if v > thresh:\n",
      "            total_predictions += 1\n",
      "\n",
      "    falsePos = total_predictions - truePos\n",
      "\n",
      "#    for (k, v) in pred_matching.iteritems():\n",
      "#        if locu[i][\"id\"] in true_matching and \\\n",
      "#                (true_matching[locu[i][\"id\"]] == \\\n",
      "#                    four[j][\"id\"]):\n",
      "#            truePos = truePos + 1\n",
      "#        else:\n",
      "#            falsePos = falsePos + 1\n",
      "            #utils.print_obj(true_matching)\n",
      "            #utils.print_obj(four[j])\n",
      "            #print(\"\\n\")\n",
      "\n",
      "    precision = truePos / float(truePos + falsePos)\n",
      "    recall = truePos / float(len(true_matching))\n",
      "    fmeas = (2.0 * precision * recall) / (precision + recall)\n",
      "\n",
      "    print \"TP = \",truePos,\"FP = \",falsePos,\"PREC = \",precision,\"RECALL = \",recall,\"F = \",fmeas\n",
      "\n",
      "    return missed\n",
      "\n",
      "def featurize(locu, four, sim):\n",
      "    X = []\n",
      "    index = []\n",
      "    for (k_a, a) in locu.iteritems():\n",
      "        for (k_b, b) in four.iteritems():\n",
      "            X.append(sim(a, b))\n",
      "            index.append((k_a, k_b))\n",
      "    return (X, index)\n",
      "\n",
      "def get_y(index, matches):\n",
      "    y = [] \n",
      "\n",
      "    for (k_a, k_b) in index:\n",
      "        if (k_a, k_b) in matches:\n",
      "            y.append(True)\n",
      "        else:\n",
      "            y.append(False)\n",
      "    return y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are ready to load the data!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ----------------\n",
      "# Main\n",
      "# ----------------\n",
      "# Load in the json files\n",
      "locu = utils.load_json('locu_train_hard.json')  \n",
      "four = utils.load_json('foursquare_train_hard.json') \n",
      "\n",
      "locu_test = utils.load_json('locu_test_hard.json')  \n",
      "four_test = utils.load_json('foursquare_test_hard.json') \n",
      "\n",
      "locu_easy = utils.load_json(\"locu_train.json\")\n",
      "four_easy = utils.load_json(\"foursquare_train.json\")\n",
      "\n",
      "# Read in matches\n",
      "matches_hard = utils.read_matches(\"matches_train_hard.csv\")\n",
      "\n",
      "# Remove crappy data from gold standard\n",
      "del matches_hard[(\"5f3fd107090d0ddc658b\", \"51ce011a498ed8dfb15381bb\")]\n",
      "del matches_hard[(\"c170270283ef870d546b\", \"51eb7eed498e401ec51196b6\")]\n",
      "del matches_hard[(\"493f5e2798de851ec3b2\", \"51f119e7498e9716f71f4413\")]\n",
      "del matches_hard[(\"212dffb393f745df801a\", \"51e869ac498e7e485cabcdeb\")]\n",
      "del matches_hard[(\"e3f9d84c0c989f2e7928\", \"51e25e57498e535de72f03e7\")]\n",
      "del matches_hard[(\"66ef54d76ff989a91d52\", \"51c9e1dd498e33ecd8670892\")]\n",
      "del matches_hard[(\"edeba23f215dcc702220\", \"51a11cbc498e4083823909f1\")]\n",
      "\n",
      "matches_easy = utils.read_matches(\"matches_train.csv\")\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is where we turn the raw data into features. \n",
      "\n",
      "In this application, the input data into our model is actually <i>pairs</i> of entities from the two companies' datasets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sim(x, y):\n",
      "    return [#utils.jaccard_char_score(x, y, [\"name\"]), \\\n",
      "            #utils.jaccard_char_score(x, y, [\"street_address\"]), \\\n",
      "            #utils.jaccard_score(x, y, \"street_address\"), \\\n",
      "            #utils.compute_equal_phones(x, y), \\\n",
      "            utils.distance(x, y), \\\n",
      "            #1 if (x[\"phone\"] is None) != (y[\"phone\"] is None) else 0, \\\n",
      "            #1 if (x[\"street_address\"] is None) != (y[\"street_address\"] is None) else 0, \\\n",
      "            #1 if (x[\"name\"] == y[\"name\"]) else 0, \\\n",
      "            #feature_library.compute_equal_website( x, y ) \\\n",
      "            ]\n",
      "\n",
      "import sys\n",
      "\n",
      "sys.stderr.write( \"Featurizing easy dataset...\" )\n",
      "(X_easy, index_easy) = featurize(locu_easy, four_easy, sim)\n",
      "y_easy = get_y(index_easy, matches_easy)\n",
      "sys.stderr.write( \"done.\\n\" )\n",
      "\n",
      "\n",
      "sys.stderr.write( \"Featurizing hard dataset...\" )\n",
      "(X, index) = featurize(locu, four, sim)\n",
      "y = get_y(index, matches_hard) \n",
      "sys.stderr.write( \"done.\\n\" )\n",
      "\n",
      "X_tot = X + X_easy\n",
      "y_tot = y + y_easy\n",
      "\n",
      "#clf = LogisticRegression() \n",
      "\n",
      "clf = RandomForestClassifier(n_estimators = 10, n_jobs = 2)\n",
      "\n",
      "\n",
      "sys.stderr.write( \"Fitting classifier...\" )\n",
      "clf = clf.fit(X_tot, y_tot)\n",
      "sys.stderr.write( \"done.\\n\" )\n",
      "\n",
      "## Test on training\n",
      "sys.stderr.write( \"Predicting on test data...\" )\n",
      "p = clf.predict_proba(X)\n",
      "sys.stderr.write( \"done.\\n\" )\n",
      "res = weights_to_matching(p, index)\n",
      "\n",
      "for thresh in np.linspace(0, .9, 5): \n",
      "    print(thresh)\n",
      "    missed = score_matching(res, matches_hard, thresh)\n",
      "\n",
      "    # Print missed matches\n",
      "    #for (k_a, k_b) in missed:\n",
      "    #    utils.print_obj(locu[k_a])\n",
      "    #    utils.print_obj(four[k_b])\n",
      "    #    print(res[(k_a, k_b)])\n",
      "    #    print(\"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Featurizing easy dataset...done.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Featurizing hard dataset...done.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Fitting classifier..."
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Test on testing\n",
      "thresh = 0.4\n",
      "(X_test, index_test) = featurize(locu_test, four_test, sim)\n",
      "p = clf.predict_proba(X_test)\n",
      "\n",
      "res = weights_to_matching(p, index_test)\n",
      "utils.write_matching(res, thresh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}